"# laBelup_crawler" 

크롤러 계획

1. API 이용 가능한 사이트 확인 -> ip 1개 대상으로 나오는 response값 형식 확인
2. API 이용이 불가능한 사이트 -> 직접 server로 query날려서 결과값 받아보기
3. API 이용 불가능, query도 안먹는 사이트 -> 직접 selenium을 사용하여 크롤링 -> 많은 검색에 대해 어떻게 진행할지 고민 후 진행
    -- 시간문제, 봇으로 인지 안되도록

DB 계획
위 크롤러들이 모아온 정보를 어떤 형식으로 어떻게 저장할지.
